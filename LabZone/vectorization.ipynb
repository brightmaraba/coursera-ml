{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For loop: [1.00000000e+000 2.45261912e-231 1.00000000e+000]\n",
      "Vectorized Implementation: [[1.00000000e+000 2.45261912e-231 1.00000000e+000]]\n",
      "For loop: 0.0007598400115966797\n",
      "Vectorized Implementation: 0.000133514404296875\n",
      "Faster by 82.42861625352997%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "A module that compares the runtime of a for loop and a vectorized implementation of Neural Net dense layer\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import time\n",
    "# Define the sigmoid function\n",
    "def g(z):\n",
    "    \"\"\"\n",
    "    A function that returns the sigmoid of a number\n",
    "    args:\n",
    "        z: int/float\n",
    "    returns:\n",
    "        int/float\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# For loop\n",
    "def dense(a_in, W, b):\n",
    "    \"\"\"\n",
    "    Uses a for loop to compute the output of a neural network with 1 hidden layer\n",
    "    args:\n",
    "        a_in: numpy.ndarray - (n, m)\n",
    "        W: numpy.ndarray - (m, u)\n",
    "        b: numpy.ndarray - (u,)\n",
    "    returns:\n",
    "        a_out: numpy.ndarray - (n, u)\n",
    "    \"\"\"\n",
    "    units = W.shape[1]\n",
    "    a_out = np.zeros(units)\n",
    "    for j in range(units):\n",
    "        w = W[:, j]\n",
    "        z = np.dot(a_in, w) + b[j]\n",
    "        a_out[j] = g(z)\n",
    "    return a_out\n",
    "\n",
    "x = np.array([200, 17])\n",
    "W = np.array([[1, -3, 5], [-2, 4, -6]])\n",
    "b = np.array([-1, 1, 2])\n",
    "\n",
    "f_start = time.time()\n",
    "for_output = dense(x, W, b)\n",
    "f_end = time.time()\n",
    "f_runtime = f_end -f_start\n",
    "\n",
    "# Vectorized\n",
    "def dense_vectorized(A_in, W, B):\n",
    "    \"\"\"\n",
    "    Uses a vectorized implementation to compute the output of a neural network with 1 hidden layer\n",
    "    args:\n",
    "        A_in: numpy.ndarray - (n, m)\n",
    "        W: numpy.ndarray - (m, u)\n",
    "        B: numpy.ndarray - (1, u)\n",
    "    returns:\n",
    "        A_out: numpy.ndarray - (n, u)\n",
    "    \"\"\"\n",
    "    Z = np.matmul(A_in, W) + B\n",
    "    A_out = g(Z)\n",
    "    return A_out\n",
    "\n",
    "# Capital letters are used to denote matrices and vectors\n",
    "X = np.array([[200, 17]]) # Note the 2-square brackets - 2D array\n",
    "W = np.array([[1, -3, 5], [-2, 4, -6]]) # Same here\n",
    "B = np.array([[-1, 1, 2]]) # 1*3  2D array\n",
    "\n",
    "v_start = time.time()\n",
    "vectorized_output = dense_vectorized(X, W, B)\n",
    "v_end = time.time()\n",
    "v_runtime = v_end - v_start\n",
    "\n",
    "# How much faster is the vectorized implementation?\n",
    "print(f\"For loop: {for_output}\")\n",
    "print(f\"Vectorized Implementation: {vectorized_output}\")\n",
    "faster_percent = (f_runtime - v_runtime) / f_runtime * 100\n",
    "print(f\"For loop: {f_runtime}\")\n",
    "print(f\"Vectorized Implementation: {v_runtime}\")\n",
    "print(f\"Faster by {faster_percent}%\")\n",
    "\n",
    "\n",
    "# Best case ouputs\n",
    "# For loop: 0.0006983280181884766\n",
    "# Vectorized Implementation: 9.512901306152344e-05\n",
    "# Faster by 86.3988584716077%\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-sci",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
